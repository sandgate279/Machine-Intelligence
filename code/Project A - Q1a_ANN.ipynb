{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (Tensorflow - Two spiral Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will look at a more complex classification task. The two spiral dataset consists of (x,y) coordinates of two alternating spirals, as can be seen in the following image. The aim of this exercise is to train a multilayer perceptron (MLP) to correctly classify an (x,y) coordinate.\n",
    "\n",
    "![alt text](images/two_spiral.png \"Two Spiral Dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of generating the dataset, we will read it from a file that takes the following form:\n",
    "\n",
    "|    x   |    y   | class |\n",
    "|:------:|:------:|:-----:|\n",
    "|  -6.5  |   0.0  |   0   |\n",
    "|  -6.5  |  -0.0  |   1   |\n",
    "|  6.314 |  1.256 |   0   |\n",
    "| -6.314 | -1.256 |   1   |\n",
    "|   ...  |   ...  |  ...  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "#from tools import plot_confusion_matrix\n",
    "\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from numpy import arange, round, meshgrid, resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_file(filename=\"projecta/Auto_train.csv\"):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            x.append(list(map(float, row[:-1])))\n",
    "            y.append([int(row[-1])])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = read_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3], [1], [1], [1], [1], [2], [3], [3], [1], [2], [1], [2], [3], [2], [1], [1], [1], [1], [3], [1], [2], [1], [3], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [2], [1], [3], [1], [1], [1], [3], [2], [3], [2], [3], [2], [1], [3], [3], [3], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [3], [3], [1], [3], [1], [1], [3], [2], [2], [2], [2], [2], [3], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [2], [3], [1], [1], [2], [1], [2], [1], [1], [1], [3], [2], [1], [1], [1], [1], [2], [3], [1], [3], [1], [1], [1], [1], [2], [3], [3], [3], [3], [3], [1], [3], [2], [2], [2], [2], [3], [2], [3], [2], [3], [3], [2], [1], [3], [1], [1], [1], [1], [1], [3], [1], [3], [3], [3], [3], [3], [1], [1], [1], [2], [2], [3], [3], [3], [3], [2], [2], [3], [3], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [2], [3], [3], [1], [1], [3], [3], [3], [3], [3], [3], [1], [1], [1], [1], [3], [1], [1], [1], [2], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [3], [1], [1], [1], [3], [2], [2], [2], [2], [2], [1], [1], [1], [1], [1], [3], [1], [3], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [2], [2], [2], [3], [3], [2], [1], [3], [1], [2], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [3], [1], [1], [1], [1], [2], [2], [2], [2], [1], [3], [3], [1], [3], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will build a multilayered neural network model. We will use **two** hidden layers and will therefore need three sets of weights (one connecting the input layer to the first hidden layer, another connecting the first hidden layer to the second hidden layer, and another connecting the second hidden layer to the output layer). In this example, each hidden layer is set to have 40 neurons. This is an arbitrary number -- feel free to play around with the network's configuration and change this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "x_ = tf.placeholder(tf.float32, [None, 2])\n",
    "y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "neur = 100\n",
    "\n",
    "# Create first layer weights\n",
    "layer_0_weights = tf.Variable(tf.random_normal([2, neur]))\n",
    "layer_0_bias = tf.Variable(tf.random_normal([neur]))\n",
    "layer_0 = tf.nn.sigmoid(tf.add((tf.matmul(x_, layer_0_weights)), layer_0_bias))\n",
    "\n",
    "# Create second layer weights\n",
    "layer_1_weights = tf.Variable(tf.random_normal([neur, neur]))\n",
    "layer_1_bias = tf.Variable(tf.random_normal([neur]))\n",
    "layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(layer_0, layer_1_weights), layer_1_bias))\n",
    "\n",
    "# Create second layer weights\n",
    "layer_2_weights = tf.Variable(tf.random_normal([neur, neur]))\n",
    "layer_2_bias = tf.Variable(tf.random_normal([neur]))\n",
    "layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, layer_2_weights), layer_2_bias))\n",
    "\n",
    "# Create third layer weights\n",
    "layer_3_weights = tf.Variable(tf.random_normal([neur, 1]))\n",
    "layer_3_bias = tf.Variable(tf.random_normal([1]))\n",
    "layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, layer_3_weights), layer_3_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_2:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will use the same error function and optimizer we used in the previous example and train the network in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define error function\n",
    "cost = tf.reduce_mean(tf.losses.mean_squared_error(labels=y_, predictions=layer_3))\n",
    "\n",
    "# Define optimizer and its task (minimise error function)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=.5).minimize(cost)\n",
    "\n",
    "N_EPOCHS = 50000 #Increase the number of epochs to about 50000 to get better results. This will take some time for training.\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "errors = []\n",
    "\n",
    "# Train\n",
    "for i in range(N_EPOCHS):\n",
    "    _, error = sess.run([optimizer,cost], feed_dict={x_: x, y_: y})\n",
    "    errors.append(error)\n",
    "    \n",
    "plt.plot(errors)\n",
    "plt.show()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other examples it makes sense to test the trained model on the training dataset and display the predictions alongside the targets. For this dataset, it makes more sense to display our results visually. We are going to construct our own test set of coordinates, activate on each coordinate, and then display the activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A good result is to have two, well separated, spirals. Play around with the network configuration (number of hidden layers and number of units per hidden layer) and the number of training epochs to explore how they effect model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display predictions\n",
    "classifications = round(sess.run(layer_3, feed_dict={x_: x}))\n",
    "#for input, target, prediction in zip(x, y, classifications):\n",
    "#    print(\"input\",input,\"target\",target,\"prediction\",prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y2 = np.zeros(len(y)) #np.ones((3,2))\n",
    "y2 = list(np.zeros(len(y)))           \n",
    "for i in range(0, len(y)): y2[i] = int(y[i][0]) \n",
    "    \n",
    "class2 = list(np.zeros(len(classifications))) \n",
    "for i in range(0, len(classifications)): class2[i] = int(classifications[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ee73fb7ec19e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrue_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_label\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#confusion_matrix[y2][class2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "confusion_matrix = np.zeros((2,2))\n",
    "\n",
    "for true_label, predicted_label in zip(y2, class2):\n",
    "    confusion_matrix[true_label][predicted_label] += 1\n",
    "    \n",
    "#confusion_matrix[y2][class2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,normalize,title,cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks([-0.5, 0.5, 1.5], classes, rotation=90)\n",
    "    \n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, np.round(cm[i, j],2),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 verticalalignment='center',\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "        plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tools import plot_confusion_matrix\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix, classes=['Heart Disease','No Heart Disease'], normalize=False, title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix, classes=['Heart Disease','No Heart Disease'], normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename=\"projecta/Auto_test.csv\"):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            x.append(list(map(float, row[:-1])))\n",
    "            y.append([int(row[-1])])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = read_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display predictions\n",
    "classifications = round(sess.run(layer_3, feed_dict={x_: x}))\n",
    "#for input, target, prediction in zip(x, y, classifications):\n",
    "#    print(\"input\",input,\"target\",target,\"prediction\",prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y2 = np.zeros(len(y)) #np.ones((3,2))\n",
    "y2 = list(np.zeros(len(y)))           \n",
    "for i in range(0, len(y)): y2[i] = int(y[i][0]) \n",
    "    \n",
    "class2 = list(np.zeros(len(classifications))) \n",
    "for i in range(0, len(classifications)): class2[i] = int(classifications[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros((2,2))\n",
    "\n",
    "for true_label, predicted_label in zip(y2, class2):\n",
    "    confusion_matrix[true_label][predicted_label] += 1\n",
    "    \n",
    "#confusion_matrix[y2][class2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tools import plot_confusion_matrix\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix, classes=['Heart Disease','No Heart Disease'], normalize=False, title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix, classes=['Heart Disease','No Heart Disease'], normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
